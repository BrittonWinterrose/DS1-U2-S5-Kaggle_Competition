{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "ZORU0qK14eaX",
    "outputId": "ed01a1b9-1f77-4113-f161-ce041a2060b9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import cos, sin\n",
    "\n",
    "#!pip install category_encoders\n",
    "#!pip install xgboost \n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 889
    },
    "colab_type": "code",
    "id": "W5PFxqBN3l1q",
    "outputId": "8d4d9884-ba23-464b-c740-cd0c9d476719"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../input/train_features.csv\", header=0)\n",
    "\n",
    "df = pd.read_csv(\"train_features.csv\", header=0)\n",
    "df_test = pd.read_csv(\"test_features.csv\",header=0)\n",
    "df_labels = pd.read_csv(\"train_labels.csv\", header=0)\n",
    "df_labels['status_group'].value_counts()\n",
    "df = df.merge(df_labels, on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the most voted answer we can easily define a function that gives us a dataframe to preview the missing values and the % of missing values in each column:\n",
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns\n",
    "    \n",
    "missing_values_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how many objects there are in all object columns. \n",
    "counts_ = []\n",
    "features = list(df.select_dtypes(include=['object']))\n",
    "for x in features: counts_.append(df[x].nunique());\n",
    "print(f'Encoding will create ~ {sum(counts_)} new features.')\n",
    "print(f'Encoding will also delete {len(features)} features')\n",
    "\n",
    "fc = []\n",
    "for x in features: fc.append([x, df[x].nunique()])\n",
    "\n",
    "pd.DataFrame(data=fc, columns = ['features','counts']).sort_values(by=['counts']).set_index(['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode my Y label and return a list of my labels. \n",
    "def labeler(dataframe, column):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    dataframe =  dataframe.copy()\n",
    "    le = LabelEncoder()\n",
    "    dataframe['labels'] = le.fit_transform(dataframe[column])\n",
    "    labels = [0,1,2]\n",
    "    label_names = list(le.inverse_transform(labels))\n",
    "    label_list = [labels, label_names]\n",
    "    return dataframe['labels'], label_list\n",
    "\n",
    "# Turn Lat/Long into x,y,z, coord plane. \n",
    "def lat_long(dataframe):\n",
    "    from math import cos, sin \n",
    "    dataframe =  dataframe.copy()\n",
    "    dataframe['x_coord'] = dataframe.latitude.apply(lambda x: cos(x)) * dataframe.longitude.apply(lambda x: cos(x))\n",
    "    dataframe['y_coord'] = dataframe.latitude.apply(lambda x: cos(x)) * dataframe.longitude.apply(lambda x: sin(x))\n",
    "    dataframe['z_coord'] = dataframe.latitude.apply(lambda x: sin(x))\n",
    "    dataframe = dataframe.drop(columns=['latitude', 'longitude'])\n",
    "    return dataframe\n",
    "\n",
    "# Fix silly boolean issue. \n",
    "def no_bool(dataframe, columns):\n",
    "    dataframe =  dataframe.copy()\n",
    "    for column in columns:\n",
    "        dataframe[column] = dataframe[column].replace({True: 'Yes', False: 'No'})\n",
    "    return dataframe\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix or Enhance Features\n",
    "data = df\n",
    "data = lat_long(df)\n",
    "data = no_bool(data, ['permit', 'public_meeting'])\n",
    "\n",
    "# Define those datasets\n",
    "X = data.drop(columns=['id', 'status_group','scheme_name', 'recorded_by',])\n",
    "y, label_list = labeler(df, 'status_group')\n",
    "y.head()\n",
    "\n",
    "# First passthrough features. These are any I don't want to mess with. \n",
    "passthrough_features = []\n",
    "\n",
    "# Ones to binary encode (high cardinality)\n",
    "binary_features = ['date_recorded','lga','funder','installer', 'subvillage', 'wpt_name']\n",
    "\n",
    "# Ones that aren't actually numeric.\n",
    "not_numeric = ['region_code', 'district_code']\n",
    "\n",
    "# Defining my one-hot variables. \n",
    "one_hot_features = list(X.select_dtypes(include=['object']))\n",
    "for x in binary_features: one_hot_features.remove(x)\n",
    "for x in not_numeric: one_hot_features.append(x)\n",
    "\n",
    "# Define my numeric features\n",
    "numeric_features = list(X.select_dtypes(include=['float64', 'int64']))\n",
    "for x in not_numeric: numeric_features.remove(x)\n",
    "one_hot_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQGZUUjl3jw6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, RobustScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import f_classif, chi2, SelectKBest\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from category_encoders.hashing import HashingEncoder\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Preprocessing pipelines for both numeric and categorical data.\n",
    "# Using column_transformer https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "\n",
    "\n",
    "# Define my custom pipeline functions for each type of data. Columns not expressly included are dropped.  \n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "polynom_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('polynom', PolynomialFeatures())])\n",
    "\n",
    "one_hot_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ordinal', OrdinalEncoder()),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('binary', BinaryEncoder(drop_invariant=True))])\n",
    "\n",
    "\n",
    "# Create preprocessor pipeline\n",
    "PreProcessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "#        ('pass', 'passthrough', passthrough_features),\n",
    "        ('biy', binary_transformer, binary_features),\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('o-h', one_hot_transformer, one_hot_features)\n",
    "    ],\n",
    "    n_jobs = -2)\n",
    "\n",
    "# Lets test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Train Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "PreProcessor.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(PreProcessor,  LogisticRegression())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 266 candidates, totalling 1330 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   3 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-2)]: Done  10 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-2)]: Done  19 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-2)]: Done  39 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-2)]: Done  50 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-2)]: Done  63 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-2)]: Done  76 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-2)]: Done  91 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-2)]: Done 106 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-2)]: Done 123 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-2)]: Done 140 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-2)]: Done 159 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-2)]: Done 178 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-2)]: Done 199 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-2)]: Done 220 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-2)]: Done 243 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-2)]: Done 266 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-2)]: Done 291 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-2)]: Done 316 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-2)]: Done 343 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-2)]: Done 370 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-2)]: Done 399 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-2)]: Done 428 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-2)]: Done 459 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-2)]: Done 490 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-2)]: Done 523 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-2)]: Done 556 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-2)]: Done 591 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-2)]: Done 626 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-2)]: Done 663 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-2)]: Done 700 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-2)]: Done 739 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-2)]: Done 778 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-2)]: Done 819 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-2)]: Done 860 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-2)]: Done 903 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-2)]: Done 946 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-2)]: Done 991 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-2)]: Done 1036 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-2)]: Done 1083 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-2)]: Done 1130 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-2)]: Done 1179 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-2)]: Done 1228 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-2)]: Done 1279 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-2)]: Done 1330 out of 1330 | elapsed: 16.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.753\n",
      "model score: 0.702\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(\n",
    "    PreProcessor, \n",
    "    SelectKBest(f_classif), \n",
    "    RidgeClassifier())\n",
    "\n",
    "param_grid = {\n",
    "    'selectkbest__k': range(1, len(X_train.columns)+1), \n",
    "    'ridgeclassifier__alpha': [0.001, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "    }\n",
    "\n",
    "# Fit on the train set, with grid search cross-validation\n",
    "gs = GridSearchCV(pipe, param_grid=param_grid, cv=5, \n",
    "                      scoring='accuracy', \n",
    "                      verbose=10, n_jobs=-2)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % gs.score(X_train, y_train))\n",
    "print(\"model score: %.3f\" % gs.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 152 candidates, totalling 456 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   3 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-2)]: Done  10 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-2)]: Done  19 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-2)]: Done  39 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-2)]: Done  50 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-2)]: Done  63 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-2)]: Done  76 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-2)]: Done  91 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=-2)]: Done 106 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-2)]: Done 123 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-2)]: Done 140 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-2)]: Done 159 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-2)]: Done 178 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-2)]: Done 199 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-2)]: Done 220 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-2)]: Done 243 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-2)]: Done 266 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-2)]: Done 291 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-2)]: Done 316 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-2)]: Done 343 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-2)]: Done 370 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-2)]: Done 399 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-2)]: Done 428 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-2)]: Done 456 out of 456 | elapsed:  4.4min finished\n",
      "/home/britton/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/britton/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.717\n",
      "model score: 0.707\n"
     ]
    }
   ],
   "source": [
    "pipe2 = make_pipeline(\n",
    "    PreProcessor, \n",
    "    SelectKBest(f_classif), \n",
    "    LogisticRegression())\n",
    "\n",
    "param_grid2 = {\n",
    "    'selectkbest__k': range(1, len(X_train.columns)+1), \n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10]\n",
    "    }\n",
    "\n",
    "# Fit on the train set, with grid search cross-validation\n",
    "gs2 = GridSearchCV(pipe2, param_grid=param_grid2, cv=3, \n",
    "                      scoring='accuracy', \n",
    "                      verbose=10, n_jobs=-2)\n",
    "gs2.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % gs2.score(X_train, y_train))\n",
    "print(\"model score: %.3f\" % gs2.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 760 candidates, totalling 2280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   3 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-2)]: Done  10 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-2)]: Done  19 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-2)]: Done  39 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-2)]: Done  50 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=-2)]: Done  63 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-2)]: Done  76 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-2)]: Done  91 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-2)]: Done 106 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-2)]: Done 123 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-2)]: Done 140 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-2)]: Done 159 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-2)]: Done 178 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-2)]: Done 199 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-2)]: Done 220 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-2)]: Done 243 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-2)]: Done 266 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-2)]: Done 291 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-2)]: Done 316 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-2)]: Done 343 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-2)]: Done 370 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-2)]: Done 399 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-2)]: Done 428 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-2)]: Done 459 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-2)]: Done 490 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-2)]: Done 523 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-2)]: Done 556 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-2)]: Done 591 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-2)]: Done 626 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-2)]: Done 663 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-2)]: Done 700 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-2)]: Done 739 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-2)]: Done 778 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-2)]: Done 819 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-2)]: Done 860 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-2)]: Done 903 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-2)]: Done 946 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-2)]: Done 991 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-2)]: Done 1036 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-2)]: Done 1083 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-2)]: Done 1130 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-2)]: Done 1179 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-2)]: Done 1228 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-2)]: Done 1279 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-2)]: Done 1330 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-2)]: Done 1383 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-2)]: Done 1436 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-2)]: Done 1491 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-2)]: Done 1546 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-2)]: Done 1603 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-2)]: Done 1660 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-2)]: Done 1719 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-2)]: Done 1778 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-2)]: Done 1839 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-2)]: Done 1900 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-2)]: Done 1963 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-2)]: Done 2026 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-2)]: Done 2091 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=-2)]: Done 2156 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=-2)]: Done 2223 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=-2)]: Done 2280 out of 2280 | elapsed: 29.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.699\n",
      "model score: 0.691\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "XGPipe = make_pipeline(PreProcessor, SelectKBest(f_classif), XGBClassifier())\n",
    "\n",
    "param_grid = {\n",
    "    'selectkbest__k': range(1, len(X_train.columns)+1), \n",
    "    'xgbclassifier__learning_rate':[0.001, 0.0045, 0.0065, 0.010], \n",
    "    'xgbclassifier__reg_lambda':[0, 0.01, 0.10, 0.50, 1]\n",
    "    }\n",
    "grid = {}\n",
    "\n",
    "\n",
    "# Fit on the train set, with grid search cross-validation\n",
    "XGsearch = GridSearchCV(XGPipe, param_grid=param_grid, cv=3, \n",
    "                      scoring='accuracy', \n",
    "                      verbose=10, n_jobs=-2)\n",
    "XGsearch.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % XGsearch.score(X_train, y_train))\n",
    "print(\"model score: %.3f\" % XGsearch.score(X_val, y_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#scores = cross_validate(clf, X, y, cv=3, n_jobs=-2, scoring='accuracy',return_train_score=True, return_estimator=True)\n",
    "#print(scores)\n",
    "#print('Accuracy: %.3f stdev: %.2f' % (np.mean(np.abs(scores)), np.std(scores)))\n",
    "#clf.fit(X_train,y_train)\n",
    "\n",
    "# You can just drop it into a pandas dataframe and BOOM: pretty print! \n",
    "# pd.DataFrame(scores).rename(columns={\"test_score\": 'validation_score'})\n",
    "# The test score is actually the scores from each validation cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "clf7 = make_pipeline(PreProcessor, RFECV(estimator=XGBClassifier(), step=1, min_features_to_select=1, cv=3, scoring='accuracy', verbose=10, n_jobs=-2))\n",
    "clf7.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf7.score(X_train, y_train))\n",
    "print(\"model score: %.3f\" % clf7.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "clf8 = make_pipeline(PreProcessor, RFECV(estimator=LogisticRegression(), step=1, min_features_to_select=1, cv=3, scoring='accuracy', verbose=10, n_jobs=-2))\n",
    "clf8.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf8.score(X_train, y_train))\n",
    "print(\"model score: %.3f\" % clf8.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TlZG8ps43l_M"
   },
   "outputs": [],
   "source": [
    "# Rewriting my Dummy Regression Baseline one as a function\n",
    "def baseline(data):\n",
    "    name = \"Dummy Regression Baseline\"\n",
    "    # Split data into train and test\n",
    "    X_train, X_test, y_train, y_test = split(data)\n",
    "\n",
    "    # Define an estimator and param_grid\n",
    "    # WHEN DEFINING YOU CAN GIVE IT A NAME OTHERWISE IT WILL USE THE PIPELINE NAME AUTOGEN NAME (name of the function but lowercase)\n",
    "    pipe = make_pipeline(\n",
    "        PreProcesser(), \n",
    "        DummyRegressor(strategy='mean'))\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    scorer = 'MAE'\n",
    "\n",
    "    ### Get the scores with the MAE Function\n",
    "    y_pred_train = pipe.predict(X_train)  \n",
    "    y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "    train_score = mean_absolute_error(y_train, y_pred_train)\n",
    "    test_score = mean_absolute_error(y_test, y_pred_test)\n",
    "    score_variance = test_score - train_score\n",
    "    cv_score = 0.0000000000000\n",
    "    best_params = pipe.get_params\n",
    "    best_estimator = \"\"\n",
    "    selected_names = list(X_train.columns)\n",
    "    unselected_names = []\n",
    "\n",
    "    return [name, scorer, train_score, test_score, score_variance, cv_score, selected_names, unselected_names, best_params, best_estimator]\n",
    "\n",
    "\n",
    "# Rewriting my GridSearch CV as a function \n",
    "def compare(data, name):\n",
    "    X_train, X_test, y_train, y_test = split(data)\n",
    "\n",
    "    pipe = make_pipeline(\n",
    "        PreProcessor, \n",
    "        SelectKBest(f_regression), \n",
    "        Ridge())\n",
    "\n",
    "    param_grid = {\n",
    "        'selectkbest__k': range(1, len(X_train.columns)+1), \n",
    "        'ridge__alpha': [0.1, 1.0, 10.]\n",
    "    }\n",
    "\n",
    "    scorer = 'MAE'\n",
    "\n",
    "    # Fit on the train set, with grid search cross-validation\n",
    "    gs = GridSearchCV(pipe, param_grid=param_grid, cv=3, \n",
    "                      scoring='neg_mean_absolute_error', \n",
    "                      verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    train_score = -gs.score(X_train, y_train)\n",
    "    test_score = -gs.score(X_test, y_test)\n",
    "    score_variance = test_score - train_score\n",
    "    cv_score = -gs.best_score_\n",
    "    best_params = gs.best_params_\n",
    "    best_estimator = gs.best_estimator_\n",
    "\n",
    "    # selected features? \n",
    "    # 'selectkbest' is the autogenerated name of the SelectKBest() function in the pipeline\n",
    "    selector = gs.best_estimator_.named_steps['selectkbest']\n",
    "    all_names = X_train.columns\n",
    "\n",
    "    # get_support returns a mask of the columns in True / False\n",
    "    selected_mask = selector.get_support()\n",
    "    # Passing the boolean list as the column names creates a masked list.  \n",
    "    selected_names = list(all_names[selected_mask])\n",
    "    unselected_names = list(all_names[~selected_mask])\n",
    "\n",
    "    return [name, scorer, train_score, test_score, score_variance, cv_score, selected_names, unselected_names, best_params, best_estimator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\n",
    "submission = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':predictions})\n",
    "\n",
    "#Visualize the first 5 rows\n",
    "submission.head()\n",
    "\n",
    "#Convert DataFrame to a csv file that can be uploaded\n",
    "#This is saved in the same directory as your notebook\n",
    "filename = 'Titanic Predictions 1.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled13.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
